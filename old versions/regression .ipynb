{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = 0.53\n",
    "\n",
    "sehirler=[\"Adana\", \"Adıyaman\", \"Afyon\", \"Ağrı\", \"Amasya\", \"Ankara\", \"Antalya\", \"Artvin\", \"Aydın\", \"Balıkesir\", \n",
    "          \"Bilecik\", \"Bingöl\", \"Bitlis\", \"Bolu\", \"Burdur\", \"Bursa\", \"Çanakkale\", \"Çankırı\", \"Çorum\", \"Denizli\", \n",
    "          \"Diyarbakır\", \"Edirne\", \"Elazığ\", \"Erzincan\", \"Erzurum\", \"Eskişehir\", \"Gaziantep\", \"Giresun\", \"Gümüşhane\", \n",
    "          \"Hakkari\", \"Hatay\", \"Isparta\", \"Mersin\", \"İstanbul\", \"İzmir\", \"Kars\", \"Kastamonu\", \"Kayseri\", \"Kırklareli\", \n",
    "          \"Kırşehir\", \"Kocaeli\", \"Konya\", \"Kütahya\", \"Malatya\", \"Manisa\", \"Kahramanmaraş\", \"Mardin\", \"Muğla\", \"Muş\", \n",
    "          \"Nevşehir\", \"Niğde\", \"Ordu\", \"Rize\", \"Sakarya\", \"Samsun\", \"Siirt\", \"Sinop\", \"Sivas\", \"Tekirdağ\", \"Tokat\", \n",
    "          \"Trabzon\", \"Tunceli\", \"Şanlıurfa\", \"Uşak\", \"Van\", \"Yozgat\", \"Zonguldak\", \"Aksaray\", \"Bayburt\", \"Karaman\", \n",
    "          \"Kırıkkale\", \"Batman\", \"Şırnak\", \"Bartın\", \"Ardahan\", \"Iğdır\", \"Yalova\", \"Karabük\", \"Kilis\", \"Osmaniye\", \"Düzce\"]\n",
    "\n",
    "for i in range(len(sehirler)):\n",
    "    sehirler[i] = sehirler[i].lower()\n",
    "    sehirler[i] = sehirler[i].replace('i̇','i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression, Lasso, QuantileRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy_calculate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_calculate(actual_values, predicted_values):\n",
    "\n",
    "  comparison = abs(np.round(predicted_values) - actual_values)\n",
    "  accuracy = 1- ((len(comparison[comparison>=(0+1)])) / len(actual_values))\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean_iou_calculator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou_calculator(actual_values, predicted_values, time):\n",
    "  confusion_array = confusion_matrix(actual_values, predicted_values)\n",
    "  individual_ious = []\n",
    "  for i in range(len(confusion_array)):\n",
    "    individual_iou = confusion_array[i][i] / (sum(confusion_array[i]))\n",
    "    individual_ious.append(individual_iou)\n",
    "  mean_iou = sum(individual_ious)/len(individual_ious)\n",
    "  results = pd.DataFrame()  \n",
    "  featue_y_values = sorted(data[time].unique())\n",
    "  for i in range(len(individual_ious)):\n",
    "    results.insert(0, 'iou_(' + str(featue_y_values[i])  +')', [individual_ious[i]], True)\n",
    "  results = results[results.columns[::-1]]\n",
    "  results.insert(0, 'mean_iou', mean_iou, True)\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egeme\\AppData\\Local\\Temp\\ipykernel_17160\\3280315253.py:30: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data2['town'] = data2['town'].str.replace('.','missing')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>company</th>\n",
       "      <th>amount</th>\n",
       "      <th>town</th>\n",
       "      <th>type</th>\n",
       "      <th>week day</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K477</td>\n",
       "      <td>T-029</td>\n",
       "      <td>1</td>\n",
       "      <td>bursa</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K669</td>\n",
       "      <td>T-016</td>\n",
       "      <td>1</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>cum</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K75</td>\n",
       "      <td>T-018</td>\n",
       "      <td>1</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>çrş</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K669</td>\n",
       "      <td>T-016</td>\n",
       "      <td>1</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K513</td>\n",
       "      <td>T-034</td>\n",
       "      <td>1</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>sal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>K522</td>\n",
       "      <td>T-034</td>\n",
       "      <td>960</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>sal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>K730</td>\n",
       "      <td>T-060</td>\n",
       "      <td>960</td>\n",
       "      <td>tekirdağ</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>K788</td>\n",
       "      <td>T-060</td>\n",
       "      <td>960</td>\n",
       "      <td>tekirdağ</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>K1117</td>\n",
       "      <td>T-0211</td>\n",
       "      <td>960</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>sal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>K407</td>\n",
       "      <td>T-0133</td>\n",
       "      <td>964</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1116 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product company  amount      town  type week day  time\n",
       "0       K477   T-029       1     bursa     1      pts     2\n",
       "1       K669   T-016       1  istanbul     1      cum     4\n",
       "2        K75   T-018       1  istanbul     1      çrş     1\n",
       "3       K669   T-016       1  istanbul     1      pts     1\n",
       "4       K513   T-034       1  istanbul     1      sal     1\n",
       "...      ...     ...     ...       ...   ...      ...   ...\n",
       "1111    K522   T-034     960  istanbul     1      sal     1\n",
       "1112    K730   T-060     960  tekirdağ     1      pts     4\n",
       "1113    K788   T-060     960  tekirdağ     1      pts     4\n",
       "1114   K1117  T-0211     960   kocaeli     1      sal     1\n",
       "1115    K407  T-0133     964  istanbul     1      pts     1\n",
       "\n",
       "[1116 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('gulle.csv', sep=';', encoding = \"utf8\")\n",
    "data.columns = ['product', 'amount', 'company', 'town', 'type', 'order date', 'delivery date', 'time'] #Rearannge the dataframe as the old one\n",
    "\n",
    "data2 = data.drop('delivery date', axis = 1)\n",
    "data2[\"order day\"] = ''\n",
    "data2[\"order month\"] = ''\n",
    "data2[\"week day\"] = ''\n",
    "\n",
    "\n",
    "# Remove 'order date' and add 'order day', 'order month' and 'week day' features\n",
    "for i in range(len(data2)):\n",
    "  data2.at[i, 'order day'] = data2['order date'][i].split()[0]\n",
    "  data2.at[i, 'order month'] = data2['order date'][i].split()[1]\n",
    "  data2.at[i, 'week day'] = data2['order date'][i].split()[-1]\n",
    "data2 = data2.drop('order date', axis = 1)\n",
    "data2['week day'] = data2['week day'].str.replace('Pazartesi','pts')\n",
    "data2['week day'] = data2['week day'].str.replace('Salı','sal')\n",
    "data2['week day'] = data2['week day'].str.replace('Çarşamba','çrş')\n",
    "data2['week day'] = data2['week day'].str.replace('Perşembe','prş')\n",
    "data2['week day'] = data2['week day'].str.replace('Cumartesi','cts')\n",
    "data2['week day'] = data2['week day'].str.replace('Cuma','cum')\n",
    "data2['week day'] = data2['week day'].str.replace('Pazar','paz')\n",
    "\n",
    "# data2 = data2[data2[\"week day\"].str.contains(\"Pazar\") == False]\n",
    "\n",
    "# Rearranging Dataframe\n",
    "data2 = data2[['product', 'company', 'amount', 'town', 'type', 'order day', 'week day', 'order month', 'time']]\n",
    "data2['town'] = data2['town'].str.lower()\n",
    "data2['town'] = data2['town'].str.replace('i̇','i')\n",
    "data2['town'] = data2['town'].str.replace('.','missing')\n",
    "data2['town'] = data2['town'].str.replace(' tekirdağ','tekirdağ')\n",
    "data2['town'] = data2['town'].str.replace('küçükçekmece','istanbul')\n",
    "data2['town'] = data2['town'].str.replace('çorlu','tekirdağ')\n",
    "data2['town'] = data2['town'].str.replace('bandirma','balıkesir')\n",
    "\n",
    "#data2 = data2.drop('town',axis = 1).reset_index(drop=True)\n",
    "data2 = data2.drop('order day',axis = 1).reset_index(drop=True)\n",
    "data2 = data2.drop('order month',axis = 1).reset_index(drop=True)\n",
    "data2 = data2.fillna(\"missing\")\n",
    "#data2 = data2[data2[\"town\"].str.contains(\"missing\") == False]\n",
    "\n",
    "data_clean = data2.copy()\n",
    "drop_df = data2.copy()\n",
    "drop_index_list = []\n",
    "\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of abroad companies and products that are supplied from abroad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abroad company list:  ['T-0142' 'MZ-401']\n",
      "abroad product list:  ['K730' 'K390' 'MRL313' 'K1046' 'K143' 'K664' 'K9' 'K389' 'K256' 'K395']\n"
     ]
    }
   ],
   "source": [
    "abr = [item for item in data2[\"town\"].unique() if item not in sehirler]\n",
    "abr_str = \"\"\n",
    "\n",
    "for i in range (len(abr)):\n",
    "    abr_str = abr_str + \"|\" + abr[i]\n",
    "abr_str = abr_str[1:]\n",
    "\n",
    "if len(abr) != 0:\n",
    "    data3 = data2[data2[\"town\"].astype('str').str.contains(abr_str) == True]\n",
    "    abr_comp_list = data3[\"company\"].unique()\n",
    "    abr_prod_list = data3[\"product\"].unique()\n",
    "    print(\"abroad company list: \",abr_comp_list)\n",
    "    print(\"abroad product list: \",abr_prod_list)\n",
    "else:\n",
    "    print(\"no abroad company\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove insufficient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_insuff(df, ft):\n",
    "    print(\"removing insufficient data for \", ft, \"...\")\n",
    "    fst_len = len(df)\n",
    "    x = df[ft].value_counts() < 5 \n",
    "    df2 = x.to_frame().reset_index()\n",
    "    df2.columns = [ft, 'booly']\n",
    "    df2.drop(df2[df2.booly == False].index, inplace=True)\n",
    "    drop_list = df2[ft].tolist()\n",
    "    drop_indices=[]\n",
    "\n",
    "    if len(drop_list) != 0:\n",
    "        for i in df.index:\n",
    "            for j in range(len(drop_list)):\n",
    "                if (drop_list[j] == df.at[i, ft]):\n",
    "                    drop_indices = drop_indices + [i]\n",
    "        df.drop(drop_indices, inplace=True)\n",
    "        \n",
    "    else:\n",
    "        drop_indices = []\n",
    "                        \n",
    "    lst_len = len(df)\n",
    "    rem = fst_len - lst_len      # number of removed data\n",
    "    per = (rem / fst_len) * 100  # percentage of removed data\n",
    "\n",
    "    print(\"total number of removed data: \", rem)\n",
    "    print(\"persentage of removed data: \", round(per, 2), \"%\")\n",
    "    return df, drop_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing insufficient data for  company ...\n",
      "total number of removed data:  32\n",
      "persentage of removed data:  2.87 %\n",
      "removing insufficient data for  product ...\n",
      "total number of removed data:  169\n",
      "persentage of removed data:  15.59 %\n"
     ]
    }
   ],
   "source": [
    "data2, drop_indices = remove_insuff(data2, \"company\")\n",
    "drop_index_list = drop_index_list + drop_indices\n",
    "\n",
    "data2, drop_indices = remove_insuff(data2, \"product\")\n",
    "drop_index_list = drop_index_list + drop_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_suf = data2.copy()\n",
    "\n",
    "n_prod = data_suf[\"product\"].nunique()\n",
    "prod_list = data_suf[\"product\"].unique()\n",
    "n_comp = data_suf[\"company\"].nunique()\n",
    "comp_list = data_suf[\"company\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One - Hot - Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df, ft):      ### ft = \"company\", \"product\", \"week day\" etc.\n",
    "    print(\"one hot encoding \", ft, \"...\")\n",
    "    dum = pd.get_dummies(df[ft])\n",
    "    df = df.drop(ft, axis = 1)\n",
    "    df = df.join(dum)\n",
    "    print(ft, \"encoded.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoding  week day ...\n",
      "week day encoded.\n",
      "one hot encoding  company ...\n",
      "company encoded.\n",
      "one hot encoding  product ...\n",
      "product encoded.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>town</th>\n",
       "      <th>type</th>\n",
       "      <th>time</th>\n",
       "      <th>cts</th>\n",
       "      <th>cum</th>\n",
       "      <th>prş</th>\n",
       "      <th>pts</th>\n",
       "      <th>sal</th>\n",
       "      <th>çrş</th>\n",
       "      <th>...</th>\n",
       "      <th>K669</th>\n",
       "      <th>K688</th>\n",
       "      <th>K700</th>\n",
       "      <th>K730</th>\n",
       "      <th>K744</th>\n",
       "      <th>K746</th>\n",
       "      <th>K765</th>\n",
       "      <th>K788</th>\n",
       "      <th>K9</th>\n",
       "      <th>K980</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bursa</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>960</td>\n",
       "      <td>missing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>960</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>960</td>\n",
       "      <td>tekirdağ</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>960</td>\n",
       "      <td>tekirdağ</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>964</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amount      town  type  time  cts  cum  prş  pts  sal  çrş  ...  K669  \\\n",
       "0          1     bursa     1     2    0    0    0    1    0    0  ...     0   \n",
       "5          1   kocaeli     1     3    0    1    0    0    0    0  ...     1   \n",
       "6          1   kocaeli     1     3    0    0    0    1    0    0  ...     1   \n",
       "7          1   kocaeli     1     1    0    0    0    1    0    0  ...     1   \n",
       "8          1   kocaeli     1     1    0    0    1    0    0    0  ...     1   \n",
       "...      ...       ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "1110     960   missing     1     1    0    0    1    0    0    0  ...     0   \n",
       "1111     960  istanbul     1     1    0    0    0    0    1    0  ...     0   \n",
       "1112     960  tekirdağ     1     4    0    0    0    1    0    0  ...     0   \n",
       "1113     960  tekirdağ     1     4    0    0    0    1    0    0  ...     0   \n",
       "1115     964  istanbul     1     1    0    0    0    1    0    0  ...     0   \n",
       "\n",
       "      K688  K700  K730  K744  K746  K765  K788  K9  K980  \n",
       "0        0     0     0     0     0     0     0   0     0  \n",
       "5        0     0     0     0     0     0     0   0     0  \n",
       "6        0     0     0     0     0     0     0   0     0  \n",
       "7        0     0     0     0     0     0     0   0     0  \n",
       "8        0     0     0     0     0     0     0   0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...  ..   ...  \n",
       "1110     0     0     1     0     0     0     0   0     0  \n",
       "1111     0     0     0     0     0     0     0   0     0  \n",
       "1112     0     0     1     0     0     0     0   0     0  \n",
       "1113     0     0     0     0     0     0     1   0     0  \n",
       "1115     0     0     0     0     0     0     0   0     0  \n",
       "\n",
       "[915 rows x 86 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2  = one_hot(data2, \"week day\")\n",
    "data2  = one_hot(data2, \"company\")\n",
    "data2  = one_hot(data2, \"product\")\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df4 = data2\n",
    "x_train, x_val = train_test_split(df4, test_size = 0.2, random_state = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### değerler clean_noise fonksiyonunda kullanılıyor !!\n",
    "\n",
    "# n_prod = data2[\"product\"].nunique()\n",
    "# prod_list = data2[\"product\"].unique()\n",
    "# n_comp = data2[\"company\"].nunique()\n",
    "# comp_list = data2[\"company\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_noise(df): # df = x_train/x_test\n",
    "    in_len = len(df)\n",
    "    zs = 0.53\n",
    "        \n",
    "    print(\"Cleaning noise ... \")\n",
    "    \n",
    "    index_drop_list = []\n",
    "    for prod in prod_list:\n",
    "\n",
    "        df_max_scaled = df[df[prod] == 1].copy()\n",
    "\n",
    "        for comp in comp_list:\n",
    "            df_max_scaled2 = df_max_scaled[df_max_scaled[comp] == 1].copy()\n",
    "\n",
    "            if len(df_max_scaled2) > 1:\n",
    "                \n",
    "                max_min_t = df_max_scaled2[\"time\"].max() - df_max_scaled2[\"time\"].min()\n",
    "                max_min_a = df_max_scaled2[\"amount\"].max() - df_max_scaled2[\"amount\"].min()\n",
    "                \n",
    "                if (max_min_a != 0) and (max_min_t != 0):\n",
    "                    df_max_scaled2[\"time\"] = (df_max_scaled2[\"time\"] - df_max_scaled2[\"time\"].min()) / max_min_t\n",
    "                    t_sc = df_max_scaled2[[\"time\"]]\n",
    "                    df_zscore_t = (t_sc - t_sc.mean())/t_sc.std()\n",
    "                    dfz_t = abs(df_zscore_t) > zs\n",
    "\n",
    "                    df_max_scaled2[\"amount\"] = (df_max_scaled2[\"amount\"] - df_max_scaled2[\"amount\"].min()) / max_min_a\n",
    "                    amo_sc = df_max_scaled2[\"amount\"]\n",
    "                    df_zscore_a = (amo_sc - amo_sc.mean())/amo_sc.std()\n",
    "                    dfz_a = abs(df_zscore_a) > zs\n",
    "\n",
    "                    df1 = dfz_t[\"time\"] & dfz_a \n",
    "                    df2 = (df_zscore_t[\"time\"] * df_zscore_a) < 0 \n",
    "                    dfz = df1 & df2 \n",
    "\n",
    "                    index_drop_list = index_drop_list + [*filter(dfz.get, dfz.index)]\n",
    "\n",
    "    index_drop_list = sorted(list(set(index_drop_list)))\n",
    "    df.drop(index_drop_list, axis=0, inplace=True)\n",
    "    rem = len(index_drop_list)\n",
    "    f_len = len(df)\n",
    "    n_del = in_len - f_len\n",
    "    per = (n_del / in_len) * 100\n",
    "    \n",
    "    print(\"deleted indices: \",index_drop_list)\n",
    "    print(\"total number of removed data: \", n_del)\n",
    "    print(\"persentage of removed data: \", round(per, 2), \"%\")\n",
    "    \n",
    "    return df, index_drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning noise ... \n",
      "deleted indices:  [125, 133, 139, 163, 194, 196, 218, 228, 247, 250, 254, 255, 306, 310, 311, 317, 356, 358, 361, 372, 376, 377, 462, 475, 477, 492, 494, 508, 532, 547, 549, 581, 617, 639, 675, 684, 688, 689, 701, 703, 707, 708, 717, 720, 737, 745, 782, 787, 818, 834, 854, 871, 897, 902, 908, 939, 948, 949, 953, 955, 956, 957, 967, 972, 982, 985, 991, 1010, 1011, 1016, 1018, 1021, 1025, 1026, 1031, 1033, 1034, 1037, 1073, 1076, 1088, 1092, 1098, 1099, 1100, 1107, 1108, 1109, 1110, 1115]\n",
      "total number of removed data:  90\n",
      "persentage of removed data:  12.3 %\n",
      "Cleaning noise ... \n",
      "deleted indices:  [185, 197, 212, 433, 511, 541, 564, 578, 663, 673, 712, 744, 800, 807, 814, 945, 1012, 1014, 1017, 1024, 1075, 1089, 1096, 1101]\n",
      "total number of removed data:  24\n",
      "persentage of removed data:  13.11 %\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "x_train, train_drop_list = clean_noise(x_train)\n",
    "drop_index_list = drop_index_list + train_drop_list\n",
    "\n",
    "x_val, val_drop_list = clean_noise(x_val)\n",
    "drop_index_list = drop_index_list + val_drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(train_drop_list, axis=0, inplace=True)\n",
    "data2.drop(val_drop_list, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>company</th>\n",
       "      <th>amount</th>\n",
       "      <th>town</th>\n",
       "      <th>type</th>\n",
       "      <th>week day</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K669</td>\n",
       "      <td>T-016</td>\n",
       "      <td>1</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>cum</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K75</td>\n",
       "      <td>T-018</td>\n",
       "      <td>1</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>çrş</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K669</td>\n",
       "      <td>T-016</td>\n",
       "      <td>1</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K513</td>\n",
       "      <td>T-034</td>\n",
       "      <td>1</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>sal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K637</td>\n",
       "      <td>T-015</td>\n",
       "      <td>1</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>cum</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>K788</td>\n",
       "      <td>T-060</td>\n",
       "      <td>960</td>\n",
       "      <td>tekirdağ</td>\n",
       "      <td>1</td>\n",
       "      <td>sal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>K788</td>\n",
       "      <td>T-060</td>\n",
       "      <td>960</td>\n",
       "      <td>tekirdağ</td>\n",
       "      <td>1</td>\n",
       "      <td>prş</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>K730</td>\n",
       "      <td>T-0142</td>\n",
       "      <td>960</td>\n",
       "      <td>missing</td>\n",
       "      <td>1</td>\n",
       "      <td>prş</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>K1117</td>\n",
       "      <td>T-0211</td>\n",
       "      <td>960</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>sal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>K407</td>\n",
       "      <td>T-0133</td>\n",
       "      <td>964</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product company  amount      town  type week day  time\n",
       "1       K669   T-016       1  istanbul     1      cum     4\n",
       "2        K75   T-018       1  istanbul     1      çrş     1\n",
       "3       K669   T-016       1  istanbul     1      pts     1\n",
       "4       K513   T-034       1  istanbul     1      sal     1\n",
       "9       K637   T-015       1  istanbul     1      cum     7\n",
       "...      ...     ...     ...       ...   ...      ...   ...\n",
       "1108    K788   T-060     960  tekirdağ     1      sal     1\n",
       "1109    K788   T-060     960  tekirdağ     1      prş     1\n",
       "1110    K730  T-0142     960   missing     1      prş     1\n",
       "1114   K1117  T-0211     960   kocaeli     1      sal     1\n",
       "1115    K407  T-0133     964  istanbul     1      pts     1\n",
       "\n",
       "[315 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_index_list = sorted(list(set(drop_index_list)))\n",
    "drop_df = drop_df.loc[drop_index_list]\n",
    "drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>company</th>\n",
       "      <th>amount</th>\n",
       "      <th>town</th>\n",
       "      <th>type</th>\n",
       "      <th>week day</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K477</td>\n",
       "      <td>T-029</td>\n",
       "      <td>1</td>\n",
       "      <td>bursa</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K669</td>\n",
       "      <td>T-0211</td>\n",
       "      <td>1</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>cum</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K669</td>\n",
       "      <td>T-0211</td>\n",
       "      <td>1</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K669</td>\n",
       "      <td>T-0211</td>\n",
       "      <td>1</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K669</td>\n",
       "      <td>T-0211</td>\n",
       "      <td>1</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>prş</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>K669</td>\n",
       "      <td>T-0211</td>\n",
       "      <td>920</td>\n",
       "      <td>kocaeli</td>\n",
       "      <td>1</td>\n",
       "      <td>sal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>K788</td>\n",
       "      <td>T-060</td>\n",
       "      <td>940</td>\n",
       "      <td>tekirdağ</td>\n",
       "      <td>1</td>\n",
       "      <td>sal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>K522</td>\n",
       "      <td>T-034</td>\n",
       "      <td>960</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>1</td>\n",
       "      <td>sal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>K730</td>\n",
       "      <td>T-060</td>\n",
       "      <td>960</td>\n",
       "      <td>tekirdağ</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>K788</td>\n",
       "      <td>T-060</td>\n",
       "      <td>960</td>\n",
       "      <td>tekirdağ</td>\n",
       "      <td>1</td>\n",
       "      <td>pts</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product company  amount      town  type week day  time\n",
       "0       K477   T-029       1     bursa     1      pts     2\n",
       "5       K669  T-0211       1   kocaeli     1      cum     3\n",
       "6       K669  T-0211       1   kocaeli     1      pts     3\n",
       "7       K669  T-0211       1   kocaeli     1      pts     1\n",
       "8       K669  T-0211       1   kocaeli     1      prş     1\n",
       "...      ...     ...     ...       ...   ...      ...   ...\n",
       "1103    K669  T-0211     920   kocaeli     1      sal     1\n",
       "1104    K788   T-060     940  tekirdağ     1      sal     3\n",
       "1111    K522   T-034     960  istanbul     1      sal     1\n",
       "1112    K730   T-060     960  tekirdağ     1      pts     4\n",
       "1113    K788   T-060     960  tekirdağ     1      pts     4\n",
       "\n",
       "[801 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.drop(drop_df.index.to_list(), axis=0, inplace=True)\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(df):\n",
    "    ls = df.columns.to_list()\n",
    "    ls.remove(\"amount\")\n",
    "    df[ls] = df[ls].astype('category')\n",
    "#     df['time'] = df['time'].cat.rename_categories({1:\"1 gün\", 2:\"2 gün\", 3:\"3-4 gün\", 4:\"5-7 gün\", 5:\"8-14 gün\", 6:\"15-30 gün\", 7:\"+30 gün\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = categorize(x_train)\n",
    "# x_val = categorize(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop town column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop('town',axis = 1).reset_index(drop=True)\n",
    "x_val = x_val.drop('town',axis = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct y_train & y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = x_train[\"time\"].copy().to_frame()\n",
    "x_train.drop(\"time\", axis=1, inplace=True)\n",
    "\n",
    "y_val = x_val[\"time\"].copy().to_frame()\n",
    "x_val.drop(\"time\", axis=1, inplace=True)\n",
    "\n",
    "y_train = y_train.squeeze(axis=1)\n",
    "y_val = y_val.squeeze(axis=1)\n",
    "\n",
    "y_val = y_val.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = x_train[[\"time\"]].copy()\n",
    "# y_val = x_val[[\"time\"]].copy()\n",
    "\n",
    "# x_train.drop(\"time\", axis=1, inplace=True)\n",
    "# x_val.drop(\"time\", axis=1, inplace=True)\n",
    "\n",
    "# y_val = one_hot(y_val, \"time\")\n",
    "# #y_val = y_val.to_frame()\n",
    "\n",
    "# y_train = one_hot(y_train, \"time\")\n",
    "# #y_train = y_train.to_frame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_min = x_train[\"amount\"].min()\n",
    "xt_max = x_train[\"amount\"].max()\n",
    "\n",
    "x_train[\"amount\"] = (x_train[\"amount\"] - xt_min) / (xt_max - xt_min)\n",
    "x_val[\"amount\"] = (x_val[\"amount\"] - xt_min) / (xt_max - xt_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a df_empty with the same columns of x_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>type</th>\n",
       "      <th>cts</th>\n",
       "      <th>cum</th>\n",
       "      <th>prş</th>\n",
       "      <th>pts</th>\n",
       "      <th>sal</th>\n",
       "      <th>çrş</th>\n",
       "      <th>T-0108</th>\n",
       "      <th>T-0127</th>\n",
       "      <th>...</th>\n",
       "      <th>K669</th>\n",
       "      <th>K688</th>\n",
       "      <th>K700</th>\n",
       "      <th>K730</th>\n",
       "      <th>K744</th>\n",
       "      <th>K746</th>\n",
       "      <th>K765</th>\n",
       "      <th>K788</th>\n",
       "      <th>K9</th>\n",
       "      <th>K980</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [amount, type, cts, cum, prş, pts, sal, çrş, T-0108, T-0127, T-0129, T-0133, T-0136, T-0142, T-015, T-018, T-019, T-0210, T-0211, T-029, T-034, T-036, T-052, T-060, T-074, T-077, T22, BY-206, BY-287, BY-3562, BY-496, BY-721, BY-768, BY-788, BY-801, BY-810, BY-812, BY-834, BY-849, BY-OP02, BY-OP57, K1004, K1010, K1044, K1046, K1053, K1061, K1092, K120, K143, K148, K165, K168, K212, K240, K243, K256, K26, K28, K325, K335, K352, K389, K390, K395, K407, K477, K522, K597, K601, K607, K608, K628, K664, K669, K688, K700, K730, K744, K746, K765, K788, K9, K980]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 84 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_empty = x_train[0:0]\n",
    "df_empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pca(x_train, x_val):\n",
    "    from sklearn.decomposition import PCA\n",
    "    xl = len(x_train.columns)\n",
    "    pca = PCA(.95)\n",
    "    pca.fit(x_train)\n",
    "    print(\"number of features dropped from \", xl, \" to \", pca.n_components_) \n",
    "    #print(\"variance ratio: \", pca.explained_variance_ratio_) \n",
    "\n",
    "    x_train = pca.transform(x_train)\n",
    "    x_val = pca.transform(x_val)\n",
    "    return pca, x_train, x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTENC\n",
    "##### before pca for sure (there are categorical fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_fts(df):\n",
    "    fts = list(df.columns)\n",
    "    fts.remove('amount')\n",
    "    return fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features dropped from  84  to  43\n"
     ]
    }
   ],
   "source": [
    "pca, x_train, x_val = do_pca(x_train, x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "##### accuracy yerine R2 score gelecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 2.2729 degrees.\n",
      "Accuracy = 15.21%.\n",
      "r2:  -2.3673794867996714\n",
      "mae:  2.2728557427535017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "from pyts.datasets import load_gunpoint\n",
    "from pyts.classification import TimeSeriesForest\n",
    "\n",
    "\n",
    "regressor = SVR(kernel='poly', degree=45)\n",
    "#regressor = TimeSeriesForest(random_state=43)\n",
    "#regressor = LogisticRegression()\n",
    "regressor.fit(x_train, y_train)\n",
    "base_accuracy = evaluate(regressor, x_val, y_val)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "y_pred = regressor.predict(x_val)\n",
    "print(\"r2: \", r2_score(y_val, y_pred))\n",
    "print(\"mae: \", mean_absolute_error(y_val, y_pred))\n",
    "#print(\"acc: \", balanced_accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 1.1192 degrees.\n",
      "Accuracy = 73.71%.\n",
      "r2:  0.5216534232537167\n",
      "mae:  1.119203458117724\n"
     ]
    }
   ],
   "source": [
    "base_accuracy = evaluate(regressor, x_train, y_train)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = regressor.predict(x_train)\n",
    "print(\"r2: \", r2_score(y_train, y_pred))\n",
    "print(\"mae: \", mean_absolute_error(y_train, y_pred))\n",
    "#print(\"acc: \", balanced_accuracy_score(y_train, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "Logistic_Regression = LogisticRegression(random_state= random_state, multi_class='multinomial', max_iter = 1000).fit(x_train, y_train.astype('int'))\n",
    "rndmForest = RandomForestClassifier(n_estimators=1000, class_weight=\"balanced\", n_jobs=-1, min_samples_leaf=3, max_depth=5,\n",
    "                                    random_state=random_state).fit(x_train, y_train.astype('int'))\n",
    "                                                                   \n",
    "\n",
    "LogisticRegression_predictions = Logistic_Regression.predict(x_train)\n",
    "rndmForest_predictions = rndmForest.predict(x_train)\n",
    "\n",
    "\n",
    "print('Accuracy of LogisticRegression classifier: ', accuracy_calculate(y_train, LogisticRegression_predictions))\n",
    "print('Accuracy of RandomForest classifier: ', accuracy_calculate(y_train, rndmForest_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random_state = 42\n",
    "# # kernel = 1.0 * RBF(1.0)\n",
    "\n",
    "# # Logistic_Regression = LogisticRegression(random_state= random_state, max_iter = 1000).fit(x_train, y_train.astype('int'))\n",
    "# # #linearReg = LinearRegression().fit(x_train, y_train.astype('int'))\n",
    "# # rndmForest = RandomForestClassifier(n_estimators=1000, class_weight=\"balanced\", n_jobs=-1, min_samples_leaf=3, max_depth=5,\n",
    "# #                                     random_state=random_state).fit(x_train, y_train.astype('int'))\n",
    "                                                                   \n",
    "# # #MLP = MLPClassifier(random_state=1, max_iter=5000).fit(x_train, y_train.astype('int'))\n",
    "\n",
    "# # #Finding k value fom max accuracy\n",
    "# # k_values=[]\n",
    "# # for k in range(1, 51):\n",
    "# #     KNeighbors = KNeighborsClassifier(n_neighbors=k).fit(x_train, y_train.astype('int'))\n",
    "# #     KNeighbors_predictions = KNeighbors.predict(x_val)\n",
    "# #     k_values.append(accuracy_calculate(y_val, KNeighbors_predictions))\n",
    "\n",
    "# # k_max = k_values.index(max(k_values)) + 1\n",
    "# KNeighbors = KNeighborsClassifier(n_neighbors=k_max).fit(x_train, y_train.astype('int'))\n",
    "# CSupportVector = make_pipeline(StandardScaler(), SVC(gamma='auto')).fit(x_train, y_train.astype('int'))\n",
    "# DecisionTtree = DecisionTreeClassifier(random_state=0).fit(x_train, y_train.astype('int'))\n",
    "# # GaussianProcess = GaussianProcessClassifier(kernel=kernel,random_state=0).fit(x_train, y_train.astype('int'))\n",
    "# # AdaBoost = AdaBoostClassifier(n_estimators=1000, random_state=0).fit(x_train, y_train.astype('int'))\n",
    "# # GaussianNaiveBayes = GaussianNB().fit(x_train, y_train.astype('int'))\n",
    "# # QuadraticDiscriminantAnalysis = QuadraticDiscriminantAnalysis().fit(x_train, y_train.astype('int'))\n",
    "\n",
    "\n",
    "LogisticRegression_predictions = Logistic_Regression.predict(x_val)\n",
    "#linearReg_predictions = linearReg.predict(x_val)\n",
    "rndmForest_predictions = rndmForest.predict(x_val)\n",
    "#MLP_predictions = MLP.predict(x_val)\n",
    "KNeighbors_predictions = KNeighbors.predict(x_val)\n",
    "CSupportVector_predictions = CSupportVector.predict(x_val)\n",
    "DecisionTtree_predictions = DecisionTtree.predict(x_val)\n",
    "# GaussianProcess_predictions = GaussianProcess.predict(x_val)\n",
    "# AdaBoost_predictions = AdaBoost.predict(x_val)\n",
    "# GaussianNaiveBayes_predictions = GaussianNaiveBayes.predict(x_val)\n",
    "# QuadraticDiscriminantAnalysis_predictions = QuadraticDiscriminantAnalysis.predict(x_val)\n",
    "\n",
    "\n",
    "print('Accuracy of LogisticRegression classifier: ', accuracy_calculate(y_val, LogisticRegression_predictions))\n",
    "#print('Accuracy of LinearRegression classifier: ', accuracy_calculate(y_val, linearReg_predictions))\n",
    "print('Accuracy of RandomForest classifier: ', accuracy_calculate(y_val, rndmForest_predictions))\n",
    "#print('Accuracy of Multi-layer Perceptron classifier: ', accuracy_calculate(y_val, MLP_predictions))\n",
    "print('Accuracy of KNeighbors classifier: ', accuracy_calculate(y_val, KNeighbors_predictions))\n",
    "print('Accuracy of CSupportVector classifier: ', accuracy_calculate(y_val, CSupportVector_predictions))\n",
    "print('Accuracy of DecisionTtree classifier: ', accuracy_calculate(y_val, DecisionTtree_predictions))\n",
    "#print('Accuracy of GaussianProcess classifier: ', accuracy_calculate(y_val, GaussianProcess_predictions))\n",
    "#print('Accuracy of AdaBoost classifier: ', accuracy_calculate(y_val, AdaBoost_predictions))\n",
    "#print('Accuracy of GaussianNaiveBayes classifier: ', accuracy_calculate(y_val, GaussianNaiveBayes_predictions))\n",
    "#print('Accuracy of QuadraticDiscriminantAnalysis classifier: ', accuracy_calculate(y_val, QuadraticDiscriminantAnalysis_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rndmForest = RandomForestClassifier(n_estimators=1000, class_weight=\"balanced\", n_jobs=-1, min_samples_leaf=3, max_depth=5,\n",
    "#                                     random_state=random_state).fit(x_train, y_train.astype('int'))\n",
    "# rndmForest_predictions = rndmForest.predict(x_val)\n",
    "# print('Accuracy of RandomForest classifier: ', accuracy_calculate(y_val, rndmForest_predictions))\n",
    "# print('Balanced_Accuracy of RandomForest classifier: ', balanced_accuracy_score(y_val, rndmForest_predictions))\n",
    "# rndmForest_predictions = rndmForest.predict(x_train)\n",
    "# print('Accuracy of RandomForest classifier: ', accuracy_calculate(y_train, rndmForest_predictions))\n",
    "# print('Balanced_Accuracy of RandomForest classifier: ', balanced_accuracy_score(y_train, rndmForest_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Accuracy / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Balanced_Accuracy of LogisticRegression classifier: ', balanced_accuracy_score(y_val, LogisticRegression_predictions))\n",
    "print('Balanced_Accuracy of RandomForest classifier: ', balanced_accuracy_score(y_val, rndmForest_predictions))\n",
    "print('Balanced_Accuracy of KNeighbors classifier: ', balanced_accuracy_score(y_val, KNeighbors_predictions))\n",
    "print('Balanced_Accuracy of CSupportVector classifier: ', balanced_accuracy_score(y_val, CSupportVector_predictions))\n",
    "print('Balanced_Accuracy of DecisionTtree classifier: ', balanced_accuracy_score(y_val, DecisionTtree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"balanced_accuracy: \",balanced_accuracy_score(y_val, LogisticRegression_predictions))\n",
    "print(\"accuracy: \",accuracy_score(y_val, LogisticRegression_predictions))\n",
    "print(\"precision: \",precision_score(y_val, LogisticRegression_predictions,average='weighted'))\n",
    "print(\"recall: \",recall_score(y_val, LogisticRegression_predictions,average='weighted'))\n",
    "print(\"f1 score: \",f1_score(y_val, LogisticRegression_predictions,average='weighted'))\n",
    "\n",
    "cm = confusion_matrix(y_val, LogisticRegression_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_iou_calculator(y_val, LogisticRegression_predictions, \"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"balanced_accuracy: \",balanced_accuracy_score(y_val, rndmForest_predictions))\n",
    "print(\"accuracy: \",accuracy_score(y_val, rndmForest_predictions))\n",
    "print(\"precision: \",precision_score(y_val, rndmForest_predictions,average='weighted'))\n",
    "print(\"recall: \",recall_score(y_val, rndmForest_predictions,average='weighted'))\n",
    "print(\"f1 score: \",f1_score(y_val, rndmForest_predictions,average='weighted'))\n",
    "\n",
    "cm = confusion_matrix(y_val, rndmForest_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_iou_calculator(y_val, rndmForest_predictions, \"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"balanced_accuracy: \",balanced_accuracy_score(y_val, KNeighbors_predictions))\n",
    "print(\"accuracy: \",accuracy_score(y_val, KNeighbors_predictions))\n",
    "print(\"precision: \",precision_score(y_val, KNeighbors_predictions,average='weighted'))\n",
    "print(\"recall: \",recall_score(y_val, KNeighbors_predictions,average='weighted'))\n",
    "print(\"f1 score: \",f1_score(y_val, KNeighbors_predictions,average='weighted'))\n",
    "\n",
    "cm = confusion_matrix(y_val, KNeighbors_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_iou_calculator(y_val, KNeighbors_predictions, \"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSupportVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"balanced_accuracy: \",balanced_accuracy_score(y_val, CSupportVector_predictions))\n",
    "print(\"accuracy: \",accuracy_score(y_val, CSupportVector_predictions))\n",
    "print(\"precision: \",precision_score(y_val, CSupportVector_predictions,average='weighted'))\n",
    "print(\"recall: \",recall_score(y_val, CSupportVector_predictions,average='weighted'))\n",
    "print(\"f1 score: \",f1_score(y_val, CSupportVector_predictions,average='weighted'))\n",
    "\n",
    "cm = confusion_matrix(y_val, CSupportVector_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_iou_calculator(y_val, CSupportVector_predictions, \"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take input and create df_inp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prod_in_data(df):\n",
    "    prods = df[\"product\"].unique()\n",
    "    prd = str(input(\"Product seç: \"))\n",
    "    if prd not in prods: \n",
    "        return False, prd\n",
    "    else:\n",
    "        return True, prd\n",
    "    \n",
    "def is_prod_in_data_drop(df, prd):\n",
    "    prods = df[\"product\"].unique()\n",
    "    if prd not in prods: \n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_input(df, prd):\n",
    "    amo = input(\"Amount: \") \n",
    "    y = False\n",
    "    while y == False:\n",
    "        if (amo.isnumeric() == False):\n",
    "            print(\"Pozitif tam sayı değer giriniz\")\n",
    "            amo = input(\"Amount: \")\n",
    "\n",
    "        else:\n",
    "            d = max(df[df[\"product\"] == prd][\"amount\"].to_list()) * 3\n",
    "            if int(amo) > d:\n",
    "                print(\"Amount yüksek abi emin misin bak !?\")\n",
    "                y_n = input(\"y / n ?\")\n",
    "                if y_n == \"y\":\n",
    "                    y = True\n",
    "                elif y_n == \"n\":\n",
    "                    amo = input(\"Amount: \")                   \n",
    "            else:\n",
    "                y = True\n",
    "    amo = int(amo)\n",
    "\n",
    "    w_days = ['pts', 'sal', 'çrş', 'prş', 'cum', 'cts', 'paz']\n",
    "    wd = str(input(\"Week day: \"))\n",
    "    z = False\n",
    "    while z == False:\n",
    "        if wd not in w_days:\n",
    "            print(\"Geçerli gün giriniz...\")\n",
    "            print(\"Geçerli günler: \", w_days)\n",
    "            wd = str(input(\"Week day: \"))\n",
    "        else:\n",
    "            z = True\n",
    "\n",
    "    typ = df[df[\"product\"] == prd][\"type\"].unique()[0] \n",
    "    comps = df[df[\"product\"] == prd][\"company\"].unique()\n",
    "    tws = df[df[\"product\"] == prd][\"town\"].unique()\n",
    "\n",
    "    df_inp = pd.DataFrame(columns = ['product', 'company', 'amount', 'town', 'type', 'week day'])\n",
    "\n",
    "    for comp in comps:\n",
    "        tw = df[(df[\"product\"] == prd) & (df[\"company\"] == comp)][\"town\"].unique()[0]\n",
    "\n",
    "        df_inp = df_inp.append({'product' : prd, 'company' : comp, 'amount' : amo, 'town' : tw,'type' : typ,\n",
    "                            'week day' : wd}, ignore_index=True)\n",
    "\n",
    "    return df_inp, comps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Input !!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    #c = True\n",
    "    cond1 = False ###\n",
    "    #while c:\n",
    "    while cond1 == False: ###\n",
    "        tf, prd = is_prod_in_data(data_clean)\n",
    "        \n",
    "        if tf:\n",
    "            df_inp, comps = take_input(data_clean, prd)\n",
    "            c = False\n",
    "            cond1 = True\n",
    "        else:\n",
    "            if (is_prod_in_data_drop(drop_df, prd) == True):\n",
    "                print(\"Güvenilir sonuç için product'a ait en az 5 giriş bulunmalıdır.\")\n",
    "                print(\"\\n\",\"Daha önce bu product alımları: \")\n",
    "                a = drop_df[drop_df[\"product\"] == prd]\n",
    "                a = a.index.to_list()\n",
    "                a = data.loc[a]\n",
    "                df_inp = display(a[['company', 'amount', 'town', 'order date', 'delivery date', 'time']].style.hide(axis='index'))\n",
    "                print (\"Ortalama miktar = \", a[\"amount\"].mean(), \"Ortalama süre = \", a[\"time\"].mean())\n",
    "                return df_inp, cond1\n",
    "    \n",
    "            else:\n",
    "                df_inp = print(\"Product bulunamadı.\")\n",
    "    if cond1:\n",
    "        df_inp  = one_hot(df_inp, \"week day\")\n",
    "        df_inp  = one_hot(df_inp, \"product\")\n",
    "        df_inp  = one_hot(df_inp, \"company\")\n",
    "\n",
    "        df_inp = df_inp.drop('town',axis = 1).reset_index(drop=True)\n",
    "\n",
    "        df_inp[\"amount\"] = (df_inp[\"amount\"] - xt_min) / (xt_max - xt_min)\n",
    "\n",
    "        df_inp = df_empty.append(df_inp)\n",
    "        df_inp = df_inp.fillna(0)\n",
    "\n",
    "        df_inp = pca.transform(df_inp)\n",
    "        \n",
    "    return df_inp, cond1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp, cond1 = run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(df_inp, cond1)\n",
    "#     if cond1:\n",
    "#         df_inp  = one_hot(df_inp, \"week day\")\n",
    "#         df_inp  = one_hot(df_inp, \"product\")\n",
    "#         df_inp  = one_hot(df_inp, \"company\")\n",
    "\n",
    "#         df_inp = df_inp.drop('town',axis = 1).reset_index(drop=True)\n",
    "\n",
    "#         df_inp[\"amount\"] = (df_inp[\"amount\"] - xt_min) / (xt_max - xt_min)\n",
    "\n",
    "#         df_inp = df_empty.append(df_inp)\n",
    "#         df_inp = df_inp.fillna(0)\n",
    "\n",
    "#         df_inp = pca.transform(df_inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cond1:\n",
    "    LR = Logistic_Regression.predict(df_inp)\n",
    "    print(LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cond1:\n",
    "    RF = rndmForest.predict(df_inp)\n",
    "    print(RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cond1:\n",
    "    KN = KNeighbors.predict(df_inp)\n",
    "    print(KN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSupportVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cond1:\n",
    "    CSV = CSupportVector.predict(df_inp)\n",
    "    print(CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collective Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cond1:\n",
    "    res = np.array([])\n",
    "    output = np.array([])\n",
    "    for i in range(len(LR)):\n",
    "        res = np.append(res, [LR[i], RF[i], KN[i], CSV[i]])\n",
    "        m = mode(res)[0][0]\n",
    "        output = np.append(output, m)\n",
    "        res = np.array([])\n",
    "    output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cond1:\n",
    "    for i in range(len(output)):\n",
    "        print(\"for company \", comps[i], \", time = \", output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inp = 0\n",
    "del(df_inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUPRC ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
